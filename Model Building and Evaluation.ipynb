{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bae4e16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf66cb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Fitness(P, NF, a = 0.6, b = 0.4):\n",
    "    \"\"\"P is the classification accuracy/detection rate, NF is the length of the selected feature, where a and b are the parameters\n",
    "    orresponding to the classification accuracy weight and quality of feature selection, a = [0, 1] and b = 1 âˆ’ a\"\"\"\n",
    "    try: \n",
    "        fitness =  a*P + b*(1/NF)\n",
    "    except ZeroDivisionError as e:\n",
    "        return a*P\n",
    "    else:\n",
    "        return fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af02ef12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perf_measure(y_actual, y_pred, value):\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "\n",
    "    for i in range(len(y_pred)): \n",
    "        if y_actual[i]==y_pred[i]==value:\n",
    "            TP += 1\n",
    "        if y_pred[i]==value and y_actual[i]!=y_pred[i]:\n",
    "            FP += 1\n",
    "        if y_actual[i]==y_pred[i]!=value:\n",
    "            TN += 1\n",
    "        if y_pred[i]!= value and y_actual[i]!=y_pred[i]:\n",
    "            FN += 1\n",
    "\n",
    "    return(TP, FP, TN, FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56358e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AAP(AC, run):\n",
    "    \"\"\"AC is the accuracy rate\"\"\"\n",
    "    return sum(AC)/run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8dd9ec8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ANF(NF, run):\n",
    "    \"\"\"NF is the number of features\"\"\"\n",
    "    return sum(NF)/run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f76616a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AC(TP, FP, TN, FN):\n",
    "    return (TP+TN)/(TP+FP+TN+FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c58cb243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can be used for MBGWO for further work\n",
    "def DR(TP,FN):\n",
    "    return TP/(TP+FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8afad2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_building(X, y_train, FS):\n",
    "    index = []\n",
    "    for i in range(41):\n",
    "        if FS[i] == 1:\n",
    "            index.append(i)\n",
    "    indices = np.r_[index]\n",
    "    Xnew_train = X[:, indices]\n",
    "    classifier.fit(Xnew_train,y_train)\n",
    "    return classifier , indices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e26cf697",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(X, y_train, X_test, y_test, FS, my_dict):\n",
    "    classifier, indices = model_building(X, y_train,FS)\n",
    "    Xnew_test = X_test[:, indices]\n",
    "    y_pred = classifier.predict(Xnew_test)\n",
    "    acc_score = accuracy_score(y_test, y_pred)*100\n",
    "    values = ['normal', 'Dos', 'Probe', 'U2R', 'R2L']\n",
    "    for value in len(values):\n",
    "        TP, FP, TN, FN = perf_measure(y_train, y_pred, value)\n",
    "        Ac = AC(TP, FP, TN, FN)\n",
    "        my_dict[value].append(Ac)\n",
    "    return my_dict , acc_score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252595bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### N = 12\n",
    "D = 41\n",
    "max_iter = 20\n",
    "lb = 0\n",
    "ub = 1\n",
    "fitness = fitness_rastrigin\n",
    "run = 1\n",
    "my_dict = {\"normal\":[],\"Dos\":[],\"Probe\":[], \"U2R\":[],\"R2L\":[]}\n",
    "fs_list = []\n",
    "scores = []\n",
    "for i in range(run):\n",
    "    X = copy.copy(X_train_scaling)\n",
    "    FS = GWO(X, fitness, D, N, max_iter, lb, ub)\n",
    "    print(sum(FS))\n",
    "    print(FS)\n",
    "    fs_list.append(FS)\n",
    "    my_dict, acc_score = generate(X, y_train, X_test_scaling, y_test, FS, my_dict)\n",
    "    socres.append(acc_score)\n",
    "\n",
    "print(\"AAP: {}\")\n",
    "values = ['normal', 'Dos', 'Probe', 'U2R', 'R2L']\n",
    "res = {\"normal\":[],\"Dos\":[],\"Probe\":[], \"U2R\":[],\"R2L\":[]}\n",
    "for value in range(values):\n",
    "    print('\\n', value)\n",
    "    print(AAP(my_dic[value],run))\n",
    "    print(ANF(fs_list, run))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
